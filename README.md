# Förderung der nachhaltigen Entwicklung künstlicher Intelligenz

Wir – Vitus Zeller, Alex Wolf, die Sustainable-Innovation-Plattform Starwings und andere - wollen hiermit an konkreten Beiträgen zu einer nachhaltigen Entwicklung der künstlichen Intelligenz arbeiten. Zum einen betrifft dies die Stiftung eines Innovationspreises. Zum anderen betrifft dies die Kommunikation des Themas in Wissenschaft und Politik in Deutschland.

In Zeiten von Klimawandel und sozialen Umbrüchen und ihren Folgen wie Flüchtlingskrise und Terror müssen wir uns über den sozialen Zusammenhalt Gedanken machen. Künstliche Intelligenz (KI) kann dazu einen Beitrag leisten, aber falsch in die Gesellschaft gebracht, wird sie Probleme verschärfen.

Der jüngste Kontext zu KI:
* Aufruf Verbot KI-Waffentechnologien (Aug, 2017): von 100 Technologen, auch zurückhaltende Protagonisten wie Stuart Russell und Jürgen Schmidhuber, bereits 2015 dasselbe Anliegen von 1000 Forschern, allerdings kein Thema dieses Papiers, weil als Konsens vorausgesetzt
* OpenAI besser als beste Menschen in Computerrollenspiel (Aug, 2017): viel komplizierter als Go, OpenAI als Vorbild für den Umgang mit KIIm Folgenden soll das Thema mit einem Schwerpunkt auf solchen Lösungsansätzen liegen, die von der jungen Technologie-treibenden Generation bereitgestellt werden könnten

Die *Veränderung der Erwerbsgesellschaft* durch KI-basierte Automatisierung: 30 Millionen Fernfahrer in den USA können nicht „einfach“ einer anderen Tätigkeit nachgehen; die Arbeitslosigkeit vieler und die Konzentration von Technologie und Kapital auf wenige könnte zu einem extremen sozialen Ungleichgewicht führen. Menschen sollten in Zukunft einer möglichst erfüllenden Tätigkeit nachgehen können. Dazu birgt KI auch Chancen.

Eine *Vergemeinschaftung von Technologie*, das heißt, die Ermöglichung des offenen Zugangs zur Technologie für alle, sollte ein wirksames Gegenmittel zur Konzentration von Kapital und Macht auf wenige Technologieführer sein. So auch der Ansatz von OpenAI. Ein reines Veröffentlichen von Programmcodes und Paketen, wie Tensorflow und ähnliche, wird aber auch in Zukunft Nutzungen auf eine technologische Elite beschränken. Kann eine Plattform wie Android, die es einer Masse an Menschen ermöglicht hat, mit eigenen Produkten und Lösungen das digitale Leben zu gestalten, auch für KI gedacht werden? Das heißt, kann es vergemeinschaftete Alternativen zu Androi und beispielsweise Apples Core ML geben? Ein „Ubuntu der KI“?

Neben technologischen Lösungen sind innovative *gesellschaftliche und politische Lösungen* gefragt, Konzepte wie, beispielsweise, das Grundeinkommen. Wenn man das konkrete politische Konzept an dieser Stelle offenlässt, stellt sich immer noch die Frage der Kommunikation und der Findung von Mehrheiten für ein solches Konzept. Es gibt in Deutschland zurzeit beinahe keine öffentliche Diskussion zum Thema, nicht mal ein öffentliches Interesse. Wie können wir diese Diskussion fördern und durch die Filterblasen zu den Menschen dringen?

Die stark von Algorithmen und *KI beeinflusste politische Meinungsbildung* der heutigen Zeit stellt uns vor große Herausforderungen. Politische Lösungen sind noch nicht in Sicht. Sind dagegen technologische Lösungen denkbar: Könnten beispielsweise die dominierenden Technologiekonzerne überzeugt werden „einseitige Information zu kennzeichnen“ oder „Alternativdarstellung einzublenden“? Algorithmisch sind solche Lösungen denkbar.

Im Kern könnte die *Entwicklung von genereller KI* unser Selbstverständnis als Menschen, zumindest zum Teil, „angreifen“. Vielen Menschen  bereitet die Vorstellung von „künstlichem Leben“ – mit Hilfe von Gentechnik designtes Leben –Unwohlsein. Ein ähnlicher Effekt kann eintreten, wenn Computer Tätigkeiten übernehmen, mit denen sich Menschen identifizieren; oder die zumindest ihren Alltag prägen. Neben dieser psychologischen, existenziellen Bedrohung ist im Prinzip auch eine physische existenzielle Bedrohung denkbar, in dem eine auf KI basierte weltweite Infrastruktur bewusst oder unbewusst in einen Zustand gebracht wird, in dem sie sich gegen Menschen wendet. Es stellt sich also die Frage, ob die Forschung an künstlicher Intelligenz ähnliche Debatten wie zum Beispiel die Gentechnologie führen sollte. Ein Meilenstein der Wissenschaftsgeschichte war die erfolgreiche Selbstregulation der genetischen Forschung nach der Asilomar Conference on Recombinant DNA im Jahr 1975. Man hatte sich darauf geeinigt, dass Experimente, die DNA verschiedener Lebewesen kombiniert, zum Großteil verboten werden sollten; erlaubte Experimente unterlagen bestimmten Auflagen und einer staatlichen Kontrolle. Können wir eine ähnliche Selbstregulation auch im Bereich der künstlichen Intelligenz diskutieren? Sollte eine solche Konferenz organisiert werden?
